# 주제: 뉴스등 방송 콘텐츠 실시간 자막 변환 기술 개발 
---

- 팀명: AICC
- 팀원: 김기흥(팀장), 박성준, 하은지
---

## 필요 기술
- 음성 및 영상 처리
- 딥러닝 네트워크(MLP, CNN)
- Python, C/C++ 프로그래밍
- Docker, Kubernetes 활용
---

## 역할 분배 (회의 중)
- 음성 신호 분리: 김기흥, 박성준, 하은지
- STT 분석 패킷 설계: 김기흥, 박성준, 하은지
- STT 엔진 구현: 김기흥, 박성준, 하은지
---

## Team-OKRs
### **뉴스 등 방송 콘텐츠 실시간 자막 변환 기술 개발** 

### 프로젝트 개요

- **프로젝트 목적:** 청각 장애인을 포함한 다양한 사용자가 방송 콘텐츠를 이해하고 접근할 수 있도록 실시간 자막 변환 서비스를 제공합니다.
- **타겟 사용자:** 청각 장애인, 다양한 언어를 사용하는 사용자, 방송 콘텐츠를 텍스트 형태로 필요로 하는 사용자 등
- **제공할 기능 및 콘텐츠:**
  - 실시간 자막 변환 기능
  - 다양한 방언 및 언어 처리 기능
  - 사용자 인터페이스를 통한 쉬운 접근성

### 목표(Objectives)

1. **실시간 자막 변환 정확도 95% 이상 달성**
2. **다양한 방언 및 언어에 대한 처리 능력 개발**

### 주요 결과(Key Results)

1. **음성 및 영상 처리 기술을 사용하여 뉴스 등 방송 콘텐츠에서 음성 신호 분리 성공률 98% 달성**
2. **STT(Speech to Text) 변환 시간을 평균 1초 이내로 단축**
3. **영어 및 한국어를 포함한 다양한 언어에 대해 STT 변환 정확도 95% 이상 달성**
4. **방언 처리를 위한 STT 엔진의 재훈련 및 fine tuning을 통해 방언 인식률 90% 이상 달성**
5. **Closed Caption(C.C) 표준을 준수하며, 방송 콘텐츠에 오버레이가 가능한 자막 제작**

### 핵심성과지표(KPIs)

1. **자막 변환 정확도**
2. **처리 시간 (STT 변환 속도)**
3. **사용자 만족도 및 접근성 평가**

주요 결과	목표치	측정 방법	달성 기준
1. 음성 및 영상 처리 기술을 사용하여 뉴스 등 방송 콘텐츠에서 음성 신호 분리 성공률	98%	음성 신호 분리 성공률 = (정확하게 분리된 음성 신호 길이 / 전체 음성 신호 길이) x 100	98% 이상의 음성 신호 분리 성공률 달성
2. STT(Speech to Text) 변환 시간	평균 1초 이내	STT 변환 시간 = 음성 입력 시작 시간 - 자막 출력 시작 시간	평균 STT 변환 시간이 1초 이내임
3. 영어 및 한국어 STT 변환 정확도	95% 이상	STT 변환 정확도 = (정확하게 변환된 텍스트 길이 / 전체 텍스트 길이) x 100	영어 및 한국어 STT
   
### 전략

- **기술 개발:** 최신 음성 및 영상 처리 기술, 딥러닝 네트워크(MLP, CNN)을 활용하여 정확도와 속도를 개선합니다.
- **재훈련 및 최적화:** Google Cloud API, AWS Transcribe 등을 활용하되, 프로젝트의 특성에 맞게 재훈련 및 최적화를 진행합니다.
- **사용자 경험 개선:** 사용자의 피드백을 정기적으로 수집하고 분석하여, 사용자 인터페이스(UI) 및 사용자 경험(UX)을 개선합니다.
- **다양성 및 포용성:** 다양한 언어와 방언을 처리할 수 있는 기능을 통해 모든 사용자가 서비스를 이용할 수 있도록 합니다.
- **보안 및 프라이버시:** 사용자 데이터의 보안과 프라이버시를 우선시하며, 이를 위한 적절한 기술적 조치를 마련합니다.
